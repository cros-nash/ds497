{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9df3df",
   "metadata": {},
   "source": [
    "# Connectionist Models of Cognition\n",
    "\n",
    "- Please work in groups of two or more and **help your group members**.\n",
    "\n",
    "- Feel free to ask the instructor **questions** as you go.\n",
    "\n",
    "- Commit and show an instructor your work before leaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d32473d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cace070",
   "metadata": {},
   "source": [
    "### General Models of Learning\n",
    "\n",
    "So far in this class, we've discussed both mental representations and cognitive processes, but we haven't said much about where these two components of the mind might come from in the first place.\n",
    "\n",
    "Understanding how the mind **learns** to represent the world and solve very different kinds of problems requires a *general* theory of learning that could apply just as much to say categorization as it does to decision making.\n",
    "\n",
    "For one possible such theory, we can take inspiration from what the mind physically uses to accomplish everything it does: the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1432c71",
   "metadata": {},
   "source": [
    "### Computing Units of the Brain\n",
    "\n",
    "<div>\n",
    "<img width=300 style=\"float:right;margin-right:40px;margin-left:20px\" src=\"https://i.pinimg.com/736x/a3/d8/72/a3d872bcf7126dcb6fdc04362187e2e7.jpg\">\n",
    "\n",
    "In the late 19th century, Camillo Golgi figured out for the first time how to visualize structure of cells—called **neurons**—that make up the brain. One original such visualization is shown on the right, and reveals that neurons are cells with long \"branches\" connecting themselves to other neurons.\n",
    "\n",
    "Later work by several researchers revealed that neurons communicate with each other using electrical signals. The diagram below shows the basic structure of a neuron.\n",
    "\n",
    "<img width=300 style=\"\" src=\"neuron.jpg\">\n",
    "\n",
    "A neuron receives multiple **input signals** through connections to other neurons called **dendrites**. The strength of each of these connections varies, and thus some signals have more influence than others. The neuron then integrates (sums) all these strength-weighted signals in its **cell body**. It then transmits that one integrated signal to other neurons via its **axon**. In simpler terms, information flows from left to right.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8a558",
   "metadata": {},
   "source": [
    "### Modeling Neurons\n",
    "\n",
    "Most of the above components of biological neurons are relatively easy to model.\n",
    "\n",
    "- For example, we can model the $i$-th input signal as a number $x_i$\n",
    "\n",
    "- Then, we can model the strength of the connection to the $i$-th input as $w_i$\n",
    "\n",
    "- The actual input to a neuron is then the original input $x_i$ weighted by $w_i$, giving the product $x_i w_i$.\n",
    "\n",
    "The stronger the signal received by the neuron, the more we say it is **activated**. \n",
    "\n",
    "We can model the activation of a single neuron with a single input as: $$a = x_1 w_1$$\n",
    "\n",
    "We can visualize this artificial neuron as:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <svg width=\"300\" height=\"150\" viewBox=\"0 0 300 150\" transform=\"scale(2, 2)\">\n",
    "        <!-- Input -->\n",
    "        <text x=\"10\" y=\"70\" font-size=\"12\" fill=\"black\">x₁ (input)</text>\n",
    "        <line x1=\"50\" y1=\"75\" x2=\"100\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Weight -->\n",
    "        <text x=\"75\" y=\"65\" font-size=\"12\" fill=\"black\">w₁</text>\n",
    "        <!-- Cell Body -->\n",
    "        <circle cx=\"120\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- <text x=\"110\" y=\"80\" font-size=\"12\" fill=\"black\">Σ</text> -->\n",
    "        <!-- Output -->\n",
    "        <line x1=\"140\" y1=\"75\" x2=\"200\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"210\" y=\"80\" font-size=\"12\" fill=\"black\">a (output)</text>\n",
    "    </svg>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd88c2a",
   "metadata": {},
   "source": [
    "**Exercise:** Create a model of a neuron using a function called `neuron_with_one_input` that takes a single input as the first argument and a single weight as the second argument and returns the activation of that neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c7278f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def neuron_with_one_input(input, weight):\n",
    "    return input * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fa539526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(neuron_with_one_input(0.5, 0.5), 0.25) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff43f7",
   "metadata": {},
   "source": [
    "**Exercise:** Calculate the activation value of a neuron with an input signal value of 0.9 and a connection strength weight of 0.5. Store the result in `activation_with_one_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4897e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "activation_with_one_input = neuron_with_one_input(0.9, 0.5)\n",
    "\n",
    "# don't change\n",
    "activation_with_one_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc3e0d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(activation_with_one_input, 0.45) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f157a",
   "metadata": {},
   "source": [
    "In real neurons, signals can either **excite** the neuron (increase its activation value), or **inhibit** the neuron (decrease its activation value). We can model excitation versus inhibition using positive and negative weights respectively.\n",
    "\n",
    "**Exercise:** Calculate the activation value of a neuron with an input signal value of 0.9 and an inhibitory connection strength weight of -0.5. Store the result in `activation_after_inhibition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a16906e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.45"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "activation_after_inhibition = neuron_with_one_input(0.9, -0.5)\n",
    "\n",
    "# don't change\n",
    "activation_after_inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "04d1282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(activation_after_inhibition, -0.45) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28283469",
   "metadata": {},
   "source": [
    "Another important feature of real neurons is that they don't always activate. Instead, input signals are accumulated until they reach a particular threshold. Once that threshold is met, the neuron activates, triggering communication with other neurons.\n",
    "\n",
    "We can describe this kind of activation pattern using what is called an **activation function**, or $\\phi$.\n",
    "\n",
    "In particular, we can define our activation function as the \"step\" function:\n",
    "\n",
    "$$\n",
    "\\phi(z) =\n",
    "\\begin{cases} \n",
    "0 & \\text{if } z < t \\\\\n",
    "1 & \\text{if } z \\geq t\n",
    "\\end{cases},\n",
    "$$\n",
    "\n",
    "where $z = x_1 * w_1$ and $t$ is an activation threshold.\n",
    "\n",
    "That is, when the excitation of the neuron is less than $t$, the neuron outputs 0. When equal to or greater than $t$, it outputs 1.\n",
    "\n",
    "**Exercise:** Create a function called `step_function` that `z` and `t` as input and returns $\\phi(z)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "57d7a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def step_function(z, t):\n",
    "    return 0 if z < t else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce624d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(step_function(0.5, 0.5), 1) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc101968",
   "metadata": {},
   "source": [
    "The function $\\phi$ is visualized below for a threshold of 2. Notice why it's called a \"step\" function. The part of the function that is a vertical line marks the position of the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "41610211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_step_function(step_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b307ca7",
   "metadata": {},
   "source": [
    "The final activation of a neuron is then redefined as: $$a = \\phi(x_1 w_1).$$\n",
    "\n",
    "That is, our artificial neuron outputs 1 when the weighted input signal is \"high enough\", and 0 otherwise.\n",
    "\n",
    "Our diagram is now:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <svg width=\"400\" height=\"150\" viewBox=\"0 0 400 150\" transform=\"scale(2, 2)\">\n",
    "        <!-- Input -->\n",
    "        <text x=\"10\" y=\"70\" font-size=\"12\" fill=\"black\">x₁ (input)</text>\n",
    "        <line x1=\"50\" y1=\"75\" x2=\"100\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Weight -->\n",
    "        <text x=\"75\" y=\"65\" font-size=\"12\" fill=\"black\">w₁</text>\n",
    "        <!-- Cell Body -->\n",
    "        <circle cx=\"120\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Line to Phi -->\n",
    "        <line x1=\"140\" y1=\"75\" x2=\"170\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Phi Circle -->\n",
    "        <circle cx=\"190\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"185\" y=\"80\" font-size=\"12\" fill=\"black\">φ</text>\n",
    "        <!-- Line to Output -->\n",
    "        <line x1=\"210\" y1=\"75\" x2=\"240\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Output -->\n",
    "        <text x=\"250\" y=\"80\" font-size=\"12\" fill=\"black\">a (output)</text>\n",
    "    </svg>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2e05",
   "metadata": {},
   "source": [
    "**Exercise:** Create a model of a neuron using a function called `neuron_with_step_act` that takes in an input, a weight, and a threshold and returns the activation of that neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cded508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def neuron_with_step_act(input, weight, threshold):\n",
    "    activation = neuron_with_one_input(input, weight)\n",
    "    return step_function(activation, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3eaf128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(neuron_with_step_act(2, 0.5, 1), 1) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d94a9",
   "metadata": {},
   "source": [
    "**Exercise:** Fill in the blanks below such that the output of the neuron will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_that_should_be_one = neuron_with_step_act(0.9, 1, 0)\n",
    "\n",
    "# do not change\n",
    "output_that_should_be_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d7a65afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(output_that_should_be_one, 1) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9eb0da",
   "metadata": {},
   "source": [
    "**Exercise:** Fill in the blanks below such that the output of the neuron will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "19f60026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_that_should_be_zero = neuron_with_step_act(0.9, 1, 1)\n",
    "\n",
    "# do not change\n",
    "output_that_should_be_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2e642137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(output_that_should_be_zero, 0) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acb64c",
   "metadata": {},
   "source": [
    "The last important property of real neurons that we haven't yet modeled is the integration of multiple signals.\n",
    "\n",
    "Multiple input signals just means multiple values $x_i$ and corresponding weights $w_i$. As we said before, these signals are integrated with a simple sum, implying a modified activation rule as follows: $$a = \\phi(\\sum_i x_i w_i).$$\n",
    "\n",
    "This simplified model of a neuron is called a **perceptron**, and was invented by the psychologist Frank Rosenblatt in 1957.\n",
    "\n",
    "For a simple example of two inputs, we can write: $$a = \\phi(x_1 w_1 + x_2 w_2).$$\n",
    "\n",
    "We can visualize this neuron as:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <br><br>\n",
    "    <svg width=\"400\" height=\"220\" viewBox=\"0 0 400 200\" transform=\"scale(2, 2)\">\n",
    "        <!-- First Input -->\n",
    "        <text x=\"10\" y=\"50\" font-size=\"12\" fill=\"black\">x₁ (input)</text>\n",
    "        <line x1=\"50\" y1=\"55\" x2=\"100\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- First Weight -->\n",
    "        <text x=\"65\" y=\"55\" font-size=\"12\" fill=\"black\">w₁</text>\n",
    "        <!-- Second Input -->\n",
    "        <text x=\"10\" y=\"112\" font-size=\"12\" fill=\"black\">x₂ (input)</text>\n",
    "        <line x1=\"50\" y1=\"100\" x2=\"100\" y2=\"85\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Second Weight -->\n",
    "        <text x=\"65\" y=\"105\" font-size=\"12\" fill=\"black\">w₂</text>\n",
    "        <!-- Cell Body with Summation -->\n",
    "        <circle cx=\"120\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"113\" y=\"80\" font-size=\"16\" fill=\"black\">Σ</text>\n",
    "        <!-- Line to Phi -->\n",
    "        <line x1=\"140\" y1=\"75\" x2=\"170\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Phi Circle -->\n",
    "        <circle cx=\"190\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"185\" y=\"80\" font-size=\"12\" fill=\"black\">φ</text>\n",
    "        <!-- Line to Output -->\n",
    "        <line x1=\"210\" y1=\"75\" x2=\"240\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Output -->\n",
    "        <text x=\"250\" y=\"80\" font-size=\"12\" fill=\"black\">a (output)</text>\n",
    "    </svg>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9457b95",
   "metadata": {},
   "source": [
    "**Exercise:** Create a model of a neuron using a function called `neuron_with_two_inputs` that takes in two inputs, two weights, and a threshold and returns the activation of that neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "76b024ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def neuron_with_two_inputs(input1, input2, weight1, weight2, threshold):\n",
    "    activations = neuron_with_one_input(input1, weight1) + neuron_with_one_input(input2, weight2)\n",
    "    return step_function(activations, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5c6bd82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(neuron_with_two_inputs(0.5, 1, 2, 1.5, 3.6), 0) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b6081",
   "metadata": {},
   "source": [
    "Now that we have a complete model of a neuron (the perceptron), let's see how we can use it to model a cognitive process of learning.\n",
    "\n",
    "Let's revisit the problem of learning to categorize a set of stimuli. In the dataframe below, each row is a stimulus (4 total), the first two columns (`feature1` and `feature2`) are (binary) features of those stimuli, and the final column (`category`) is the true category label that needs to be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fa7139f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  category\n",
       "0         0         0         0\n",
       "1         0         1         0\n",
       "2         1         0         0\n",
       "3         1         1         1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = pd.DataFrame({\n",
    "    'feature1': [0, 0, 1, 1],\n",
    "    'feature2': [0, 1, 0, 1],\n",
    "    'category': [0, 0, 0, 1]\n",
    "})\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27198844",
   "metadata": {},
   "source": [
    "We can visualize these stimuli below. Note that feature 1 represents the color of the stimulus, whereas feature 2 represents the shape of the stimulus.\n",
    "\n",
    "Also note that there is one example of category 1, and three examples of category 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c5b0dbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stimuli(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592b785",
   "metadata": {},
   "source": [
    "Previously, we used categorization models to learn to categorize such stimuli. In contrast, here we will employ the perceptron as a basic model of learning to solve the same problem.\n",
    "\n",
    "Note that we want a model that can take in stimuli (`feature1` and `feature2` value pairs) and output category labels. To accomplish this, note that we can use `feature1` and `feature2` as the inputs to the perceptron. We already know that the output of the perceptron is 0 or 1 because of the step function, so we know it outputs some kind of guess for the category label (which can also only be 0 or 1).\n",
    "\n",
    "Taking the second stimulus as our example (feature1=0, feature2=1), we can model categorization as: $$\\text{predicted category label } \\hat{y} = \\phi(0\\times w_1 + 1\\times w_2).$$\n",
    "\n",
    "What kind of guess for the category label of stimulus 2 will the above spit out? Let's see.\n",
    "\n",
    "**Exercise:** Fill in the blanks to categorize stimulus 2. We'll need to pick some values for the weights and the threshold, so use 1 for all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "91457deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not change\n",
    "# inputs for stimulus 2\n",
    "x1 = df_cat['feature1'].values[1]\n",
    "x2 = df_cat['feature2'].values[1]\n",
    "\n",
    "predicted_y = neuron_with_two_inputs(x1, x2, 1, 1, 1)\n",
    "\n",
    "# do not change\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5036b9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(predicted_y, 1) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245119d",
   "metadata": {},
   "source": [
    "The above gave an output of 1 instead of what we wanted (0). \n",
    "\n",
    "The reason is that, in addition to the inputs, the output of the perceptron depends on both the values of the weights and the value of the threshold. The process of finding the best values for these parameters (i.e., that helps us categorize correctly) is what define the process of **learning** in a perceptron.\n",
    "\n",
    "### The Perceptron Learning Algorithm\n",
    "\n",
    "Before the perceptron can start learning, it needs start with some set of initial values for $w_1$, $w_2$, and $t$. We can set them all for example at 0.1 to start.\n",
    "\n",
    "The next step is to evaluate the outputs of the model. For example, if the true label $y$ for some stimulus is $1$, but the perceptron outputs $0$, then we say that it has made an **error**. We can measure this error as $y - ŷ$, and this quantity tells us how we should modify our weights:\n",
    "\n",
    "- If $y - ŷ = 0$, then the model categorized correctly, and we don't need to update the weights.\n",
    "- If $y - ŷ = 1$, then the perceptron didn't activate when it was supposed to, and we need to increase weights to increase activation.\n",
    "- If $y - ŷ = -1$, then the perceptron activated when it wasn't supposed to, and we need to decrease weights to decrease activation.\n",
    "\n",
    "The process of updating the weight strengths that connect neurons is called **error-driven learning**.\n",
    "\n",
    "When we do increase or decrease a weight, we adjust it proportionally to its corresponding input $x$ because inputs with larger magnitudes contribute more to whatever error was made. Further, we only want to make small changes to weights at any one time so we don't overdo it. Thus, rather than updating exactly proportionally to $x$, we update by a small fixed proportion of $x$, or $ηx$, where $\\eta$ is called the **learning rate**.\n",
    "\n",
    "We can write out the full rule for updating some weight $w_{\\text{old}}$ to $w_{\\text{new}}$ as: $$w_{\\text{new}} = w_{\\text{old}} + η(y - ŷ)x.$$\n",
    "\n",
    "Let's implement it.\n",
    "\n",
    "**Exercise:** Create a function called `update_weight` that takes a single `old_weight`, `eta`, a single input `x`, `y`, and `predicted_y`, and outputs the new updated weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "037696a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def update_weight(old_weight, eta, x, y, predicted_y):\n",
    "    return old_weight + eta*(y - predicted_y)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5f87b72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(update_weight(0.5, 0.1, 1, 1, 0), 0.6) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc1402",
   "metadata": {},
   "source": [
    "The final parameter we have to update is the threshold $t$. We do that using a very similar rule:\n",
    "\n",
    "$$t_{\\text{new}} = t_{\\text{old}} - η(y - ŷ)$$\n",
    "\n",
    "There are two differences in this update rule as compared to the weight update rule. First, there is a sign flip. This is because it is *smaller* thresholds that cause the neuron to activate more easily, not larger ones (whereas in contrast it is *larger* weights that push the neuron towards activation). Second, it is not a function of any input $x$ because the threshold is independent of the inputs.\n",
    "\n",
    "Let's implement this rule as well.\n",
    "\n",
    "**Exercise:** Create a function called `update_threshold` that takes `old_threshold`, `eta`, `y`, and `predicted_y`, and outputs the new updated threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bcc647e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def update_threshold(old_threshold, eta, y, predicted_y):\n",
    "    return old_threshold - eta*(y - predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5706a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(update_threshold(0.5, 0.1, 1, 0), 0.4) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc343ed",
   "metadata": {},
   "source": [
    "The final learning algorithm for two weights is as follows:\n",
    "1. Initialize both weights as well as the threshold\n",
    "2. For each stimulus, we check if the perceptron gives the correct output\n",
    "3. If not, update both weights and the threshold\n",
    "4. Go back to 2 and repeat until accuracy stops increasing\n",
    "\n",
    "Before we can implement this algorithm, let's create a function to evaluate the accuracy of a perceptron in categorizing the stimuli in our dataset.\n",
    "\n",
    "**Exercise:** Fill in the blanks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d4d07b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(df, weight1, weight2, t):\n",
    "\n",
    "    # to counter #/4 we get right\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # go through each of the four stimuli\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        # features and correct category for this stimulus\n",
    "        x1 = row['feature1']\n",
    "        x2 = row['feature2']\n",
    "        y = row['category']\n",
    "\n",
    "        # see what the perceptron outputs for this stimulus\n",
    "        y_pred = neuron_with_two_inputs(x1, x2, weight1, weight2, t)\n",
    "\n",
    "        # if the prediction is correct, tally it up\n",
    "        if y_pred == y:\n",
    "            correct_predictions = correct_predictions + 1\n",
    "    \n",
    "    # return the accuracy %\n",
    "    accuracy = correct_predictions / len(df) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dce1094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if np.isclose(evaluate_accuracy(df_cat, 1, 1, 1), 50) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a07a7",
   "metadata": {},
   "source": [
    "Now, let's implement the entire perceptron learning algorithm.\n",
    "\n",
    "**Exercise:** Fill in the blanks below. Set the learning rate to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f7607587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.0, t: 0.2, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.0, t: 0.2, Accuracy: 50%\n",
      "w1: 0.2, w2: 0.1, t: 0.1, Accuracy: 50%\n",
      "w1: 0.2, w2: 0.1, t: 0.1, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.0, t: 0.2, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.0, t: 0.3, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.1, t: 0.2, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.1, t: 0.2, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.1, t: 0.2, Accuracy: 50%\n",
      "w1: 0.1, w2: 0.1, t: 0.3, Accuracy: 50%\n",
      "w1: 0.2, w2: 0.2, t: 0.2, Accuracy: 50%\n",
      "w1: 0.2, w2: 0.2, t: 0.2, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 50%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 75%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 25%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 50%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 75%\n",
      "w1: 0.2, w2: 0.1, t: 0.3, Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "def fit_perceptron(df):\n",
    "\n",
    "    # initial values before learning\n",
    "    curr_w1 = 0.1\n",
    "    curr_w2 = 0.1\n",
    "    curr_t = 0.1\n",
    "\n",
    "    eta = 0.1\n",
    "\n",
    "    # keep learning until all four stimuli are classified correctly\n",
    "    for learning_iteration in range(100):\n",
    "        correct_predictions = 0\n",
    "\n",
    "        # go through each of the four stimuli\n",
    "        for _, row in df.iterrows():\n",
    "\n",
    "            # features and correct category for this stimulus\n",
    "            x1 = row['feature1']\n",
    "            x2 = row['feature2']\n",
    "            y = row['category']\n",
    "            \n",
    "            # see what the perceptron outputs for this stimulus\n",
    "            y_pred = neuron_with_two_inputs(x1, x2, curr_w1, curr_w2, curr_t)\n",
    "            \n",
    "            # if incorrect, update weights and threshold\n",
    "            if y_pred != y:\n",
    "                curr_w1 = update_weight(curr_w1, eta, x1, y, y_pred)\n",
    "                curr_w2 = update_weight(curr_w2, eta, x2, y, y_pred)\n",
    "                curr_t  = update_threshold(curr_t, eta, y, y_pred)\n",
    "\n",
    "            # round params to remove floating point error\n",
    "            curr_w1, curr_w2, curr_t = round(curr_w1, 2), round(curr_w2, 2), round(curr_t, 2)\n",
    "\n",
    "            # check the accuracy after the parameter updates\n",
    "            if y_pred == y:\n",
    "                correct_predictions = correct_predictions + 1\n",
    "            current_accuracy = correct_predictions / len(df) * 100\n",
    "            \n",
    "            # print current parameters and accuracy\n",
    "            print(f'w1: {curr_w1}, w2: {curr_w2}, t: {curr_t}, Accuracy: {current_accuracy:.0f}%')\n",
    "\n",
    "            # exit once all four stimuli are classified correctly\n",
    "            if np.isclose(current_accuracy, 100.00):\n",
    "                return curr_w1, curr_w2, curr_t\n",
    "            \n",
    "    return None, None, None\n",
    "\n",
    "best_w1, best_w2, best_t = fit_perceptron(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7a5b5b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if (best_w1, best_w2, best_t) == (0.2, 0.1, 0.3) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d9c68",
   "metadata": {},
   "source": [
    "Notice that, while learning, the perceptron sometimes \"changes its mind\". For example, the first weight often moves back and forth between 0.1 and 0.2. \n",
    "\n",
    "Also notice that, eventually, accuracy reaches 100% (all four stimuli have been correctly categorized by the perceptron) and thus no more learning (parameter updating) is required.\n",
    "\n",
    "Let's think about what this means for a second. The perceptron learned to categorize stimuli without any explicit starting knowledge about prototypes or memory storage.\n",
    "\n",
    "The categorization model we learned can be visualized as:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <br><br>\n",
    "    <svg width=\"400\" height=\"220\" viewBox=\"0 0 400 200\" transform=\"scale(2, 2)\">\n",
    "        <!-- First Input -->\n",
    "        <text x=\"10\" y=\"50\" font-size=\"12\" fill=\"black\">x₁ (input)</text>\n",
    "        <line x1=\"50\" y1=\"55\" x2=\"100\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- First Weight -->\n",
    "        <text x=\"65\" y=\"55\" font-size=\"12\" fill=\"black\">0.2</text>\n",
    "        <!-- Second Input -->\n",
    "        <text x=\"10\" y=\"116\" font-size=\"12\" fill=\"black\">x₂ (input)</text>\n",
    "        <line x1=\"50\" y1=\"105\" x2=\"100\" y2=\"85\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Second Weight -->\n",
    "        <text x=\"65\" y=\"110\" font-size=\"12\" fill=\"black\">0.1</text>\n",
    "        <!-- Cell Body with Summation -->\n",
    "        <circle cx=\"120\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"113\" y=\"80\" font-size=\"16\" fill=\"black\">Σ</text>\n",
    "        <!-- Line to Phi -->\n",
    "        <line x1=\"140\" y1=\"75\" x2=\"170\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Phi Circle -->\n",
    "        <circle cx=\"190\" cy=\"75\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"185\" y=\"80\" font-size=\"12\" fill=\"black\">φ</text>\n",
    "        <text x=\"175\" y=\"50\" font-size=\"12\" fill=\"black\">t=0.3</text>\n",
    "        <!-- Line to Output -->\n",
    "        <line x1=\"210\" y1=\"75\" x2=\"240\" y2=\"75\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- Output -->\n",
    "        <text x=\"250\" y=\"80\" font-size=\"12\" fill=\"black\">a (output)</text>\n",
    "    </svg>\n",
    "</div>\n",
    "\n",
    "Importantly, the perceptron didn't just learn any pair of categories, it learned a specific pair. To see what is meant by this, let's look at the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aced4316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  category\n",
       "0         0         0         0\n",
       "1         0         1         0\n",
       "2         1         0         0\n",
       "3         1         1         1"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5201ff4",
   "metadata": {},
   "source": [
    "Observe that the only stimulus labeled as category 1 is the one where both feature1 and feature2 are both 1. This means that category 1 is defined by a strict rule: an exemplar is a member of category 1 only if both feature1 AND feature2 are 1. Otherwise, it is a member of category 0.\n",
    "\n",
    "This kind of category can also be modeled using what is called a **logical operator**. If we call this operator the **AND** operator, then:\n",
    "- $0 \\text{  AND  } 0 = 0$\n",
    "- $0 \\text{  AND  } 1 = 0$\n",
    "- $1 \\text{  AND  } 0 = 0$\n",
    "- $1 \\text{  AND  } 1 = 1$\n",
    "\n",
    "This pattern recreates our dataset exactly.\n",
    "\n",
    "In 1854, a mathematician named George Boole defined this **boolean operator** (along with several others) in a book called \"The Laws of Thought\". That is, Boole, like Aristotle, was trying to provide a mathematical model of how people think logically (think about thoughts like \"I can go to college only if I both get accepted AND have the money\"). His contribution also ended up being a major foundation of computer science.\n",
    "\n",
    "What we now know is that the perceptron can implement this operator, but more importantly, **it can learn how to implement this logic without being explicitly how to do so!**\n",
    "\n",
    "### Learning other sets of categories\n",
    "\n",
    "Another operator called the **OR** operator outputs 1 when at least one of the inputs is 1 (one \"or\" the other). We can represent its behavior using another two-category dataset like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7dba5dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  category\n",
       "0         0         0         0\n",
       "1         0         1         1\n",
       "2         1         0         1\n",
       "3         1         1         1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_or = pd.DataFrame({\n",
    "    'feature1': [0, 0, 1, 1],\n",
    "    'feature2': [0, 1, 0, 1],\n",
    "    'category': [0, 1, 1, 1]\n",
    "})\n",
    "df_or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e46aa",
   "metadata": {},
   "source": [
    "Let's run the learning algorithm on it and see what happens.\n",
    "\n",
    "**Exercise:** Fill in the blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f0516a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 50%\n",
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 75%\n",
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "or_w1, or_w2, or_t = fit_perceptron(df_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "95c2fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if (or_w1, or_w2, or_t) == (0.1, 0.1, 0.1) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7125d7",
   "metadata": {},
   "source": [
    "This time, we got lucky. Not only can the perceptron apparently implement the OR operator, it was able to do it using the starting parameters (0.1, 0.1, 0.1). Note that if we had started with different parameters that weren't quite so lucky, learning would still have to take place.\n",
    "\n",
    "Let's try another operator, called the **NAND** operator, which really just the \"opposite\" of the AND operator. That is, it outputs 1 in all cases, except for when both inputs are 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "be352c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  category\n",
       "0         0         0         1\n",
       "1         0         1         1\n",
       "2         1         0         1\n",
       "3         1         1         0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nand = pd.DataFrame({\n",
    "    'feature1': [0, 0, 1, 1],\n",
    "    'feature2': [0, 1, 0, 1],\n",
    "    'category': [1, 1, 1, 0]\n",
    "})\n",
    "df_nand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7e76e",
   "metadata": {},
   "source": [
    "**Exercise:** Fill in the blanks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "af6ec999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.1, w2: 0.1, t: 0.0, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.1, t: 0.0, Accuracy: 50%\n",
      "w1: 0.0, w2: 0.0, t: 0.1, Accuracy: 50%\n",
      "w1: 0.0, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.0, t: 0.0, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.0, t: 0.0, Accuracy: 50%\n",
      "w1: -0.1, w2: -0.1, t: 0.1, Accuracy: 50%\n",
      "w1: -0.1, w2: -0.1, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: -0.1, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: 0.0, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: 0.0, Accuracy: 25%\n",
      "w1: -0.2, w2: 0.0, t: -0.1, Accuracy: 25%\n",
      "w1: -0.1, w2: 0.0, t: -0.2, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: -0.1, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: -0.1, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: -0.1, Accuracy: 50%\n",
      "w1: -0.1, w2: -0.1, t: -0.2, Accuracy: 50%\n",
      "w1: -0.2, w2: -0.2, t: -0.1, Accuracy: 50%\n",
      "w1: -0.2, w2: -0.2, t: -0.1, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 50%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 75%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 25%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 50%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 75%\n",
      "w1: -0.2, w2: -0.1, t: -0.2, Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "nand_w1, nand_w2, nand_t = fit_perceptron(df_nand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ac7e4155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if (nand_w1, nand_w2, nand_t) == (-0.2, -0.1, -0.2) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab370ab7",
   "metadata": {},
   "source": [
    "Yet again, the perceptron was able to learn this operator, though it took a bit more learning. Also notice that this is the first perceptron that made use of negative (inhibitory) weights.\n",
    "\n",
    "Let's try one last operator, the **XOR** operator, which stands for \"exclusive OR\". This operator returns 1 when exactly one input is equal to 1, but not when both inputs are 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "27964f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  category\n",
       "0         0         0         0\n",
       "1         0         1         1\n",
       "2         1         0         1\n",
       "3         1         1         0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xor = pd.DataFrame({\n",
    "    'feature1': [0, 0, 1, 1],\n",
    "    'feature2': [0, 1, 0, 1],\n",
    "    'category': [0, 1, 1, 0]\n",
    "})\n",
    "df_xor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6995117",
   "metadata": {},
   "source": [
    "**Exercise:** Fill in the blanks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1ac5b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 50%\n",
      "w1: 0.1, w2: 0.1, t: 0.1, Accuracy: 75%\n",
      "w1: 0.0, w2: 0.0, t: 0.2, Accuracy: 75%\n",
      "w1: 0.0, w2: 0.0, t: 0.2, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.1, t: 0.1, Accuracy: 25%\n",
      "w1: 0.1, w2: 0.1, t: 0.0, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.0, t: 0.1, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.0, t: 0.1, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.1, t: 0.0, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.1, t: 0.0, Accuracy: 50%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 50%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 25%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 25%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 25%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 25%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.1, t: 0.0, Accuracy: 0%\n",
      "w1: 0.0, w2: 0.1, t: -0.1, Accuracy: 0%\n",
      "w1: -0.1, w2: 0.0, t: 0.0, Accuracy: 0%\n"
     ]
    }
   ],
   "source": [
    "xor_w1, xor_w2, xor_t = fit_perceptron(df_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ef199b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "'Test passed' if (xor_w1, xor_w2, xor_t) == (None, None, None) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6fd7fc",
   "metadata": {},
   "source": [
    "Unfortunately, the perceptron didn't seem successful this time!\n",
    "\n",
    "The final accuracy (after 100 passes through the data) is still not 100%. It turns out that additional learning doesn't help.\n",
    "\n",
    "In 1969, Marvin Minsky and Seymour Papert proved that perceptrons can't learn such operators. However, that setback is not quite the end of the road for perceptrons.\n",
    "\n",
    "An important feature of boolean operators is that they can be combined. For example, the XOR operator can be built from a combination of the others:\n",
    "\n",
    "$$x_1\\text{ XOR }x_2 = (x_1 \\text{ OR } x_2) \\text{ AND } (x_1 \\text{ NAND } x_2).$$\n",
    "\n",
    "Let's confirm this.\n",
    "\n",
    "**Exercise:** In the below dataframe, fill in the `'OR'` and `'NAND'` columns with respect to feature 1 and feature 2 as inputs. Then, fill in the final `'OR AND NAND'` column based on the filled `'OR'` and `'NAND'` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "19bf4a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>OR</th>\n",
       "      <th>NAND</th>\n",
       "      <th>OR AND NAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  OR  NAND  OR AND NAND\n",
       "0         0         0   0     1            0\n",
       "1         0         1   1     1            1\n",
       "2         1         0   1     1            1\n",
       "3         1         1   1     0            0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xor2 = pd.DataFrame({\n",
    "    'feature1':    [0, 0, 1, 1],\n",
    "    'feature2':    [0, 1, 0, 1],\n",
    "    'OR':          [0, 1, 1, 1],\n",
    "    'NAND':        [1, 1, 1, 0],\n",
    "    'OR AND NAND': [0, 1, 1, 0],\n",
    "})\n",
    "df_xor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "896f5282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test passed'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "cond1 = (df_xor2['OR'] == df_or['category']).all()\n",
    "cond2 = (df_xor2['NAND'] == df_nand['category']).all()\n",
    "cond3 = (df_xor2['OR AND NAND'] == df_xor['category']).all()\n",
    "'Test passed' if (cond1 and cond2 and cond3) else 'Test failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45c0a3",
   "metadata": {},
   "source": [
    "While a single perceptron won't do, what the above implies is that we can combine multiple perceptrons together to solve more complex problems. For example, we can combine the perceptrons that have learned AND, OR, and NAND, to implement XOR. This seems perfectly fair to do, since after all, the brain contains billions of neurons, not just one.\n",
    "\n",
    "We can visualize the set of neurons that solves the XOR problem as:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <br><br>\n",
    "    <svg width=\"600\" height=\"320\" viewBox=\"0 0 600 300\" transform=\"scale(1.5, 1.5)\">\n",
    "        <!-- Input Layer -->\n",
    "        <text x=\"10\" y=\"100\" font-size=\"12\" fill=\"black\">x₁ (input)</text>\n",
    "        <text x=\"10\" y=\"200\" font-size=\"12\" fill=\"black\">x₂ (input)</text>\n",
    "        <!-- Connections to OR Neuron -->\n",
    "        <line x1=\"70\" y1=\"100\" x2=\"150\" y2=\"80\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <line x1=\"70\" y1=\"200\" x2=\"150\" y2=\"80\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- <text x=\"100\" y=\"80\" font-size=\"12\" fill=\"black\">0.1</text> -->\n",
    "        <!-- <text x=\"100\" y=\"180\" font-size=\"12\" fill=\"black\">0.1</text> -->\n",
    "        <!-- Connections to NAND Neuron -->\n",
    "        <line x1=\"70\" y1=\"100\" x2=\"150\" y2=\"220\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <line x1=\"70\" y1=\"200\" x2=\"150\" y2=\"220\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- <text x=\"100\" y=\"140\" font-size=\"12\" fill=\"black\">-0.1</text> -->\n",
    "        <!-- <text x=\"100\" y=\"220\" font-size=\"12\" fill=\"black\">-0.1</text> -->\n",
    "        <!-- OR Neuron -->\n",
    "        <circle cx=\"170\" cy=\"80\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"163\" y=\"85\" font-size=\"16\" fill=\"black\">Σ</text>\n",
    "        <line x1=\"190\" y1=\"80\" x2=\"220\" y2=\"80\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <circle cx=\"240\" cy=\"80\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"235\" y=\"85\" font-size=\"12\" fill=\"black\">φ</text>\n",
    "        <!-- <text x=\"225\" y=\"55\" font-size=\"12\" fill=\"black\">t=0.1</text> -->\n",
    "        <!-- <text x=\"245\" y=\"40\" font-size=\"12\" fill=\"black\">\"OR\"</text> -->\n",
    "        <text x=\"245\" y=\"55\" font-size=\"12\" fill=\"black\">\"OR\"</text>\n",
    "        <!-- NAND Neuron -->\n",
    "        <circle cx=\"170\" cy=\"220\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"163\" y=\"225\" font-size=\"16\" fill=\"black\">Σ</text>\n",
    "        <line x1=\"190\" y1=\"220\" x2=\"220\" y2=\"220\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <circle cx=\"240\" cy=\"220\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"235\" y=\"225\" font-size=\"12\" fill=\"black\">φ</text>\n",
    "        <!-- <text x=\"225\" y=\"195\" font-size=\"12\" fill=\"black\">t=0.0</text> -->\n",
    "        <!-- <text x=\"245\" y=\"260\" font-size=\"12\" fill=\"black\">\"NAND\"</text> -->\n",
    "        <text x=\"245\" y=\"255\" font-size=\"12\" fill=\"black\">\"NAND\"</text>\n",
    "        <!-- Connections to AND (Output) Neuron -->\n",
    "        <line x1=\"260\" y1=\"80\" x2=\"350\" y2=\"150\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <line x1=\"260\" y1=\"220\" x2=\"350\" y2=\"150\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <!-- <text x=\"300\" y=\"100\" font-size=\"12\" fill=\"black\">0.2</text> -->\n",
    "        <!-- <text x=\"300\" y=\"200\" font-size=\"12\" fill=\"black\">0.2</text> -->\n",
    "        <!-- AND (Output) Neuron -->\n",
    "        <circle cx=\"370\" cy=\"150\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"363\" y=\"155\" font-size=\"16\" fill=\"black\">Σ</text>\n",
    "        <line x1=\"390\" y1=\"150\" x2=\"420\" y2=\"150\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <circle cx=\"440\" cy=\"150\" r=\"20\" fill=\"white\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"435\" y=\"155\" font-size=\"12\" fill=\"black\">φ</text>\n",
    "        <!-- <text x=\"425\" y=\"125\" font-size=\"12\" fill=\"black\">t=0.3</text> -->\n",
    "        <text x=\"445\" y=\"190\" font-size=\"12\" fill=\"black\">\"AND\"</text>\n",
    "        <!-- Output -->\n",
    "        <line x1=\"460\" y1=\"150\" x2=\"500\" y2=\"150\" stroke=\"black\" stroke-width=\"2\" />\n",
    "        <text x=\"510\" y=\"155\" font-size=\"12\" fill=\"black\">XOR Output</text>\n",
    "    </svg>\n",
    "</div>\n",
    "\n",
    "In this new multi-neuron model, we can see that two neurons take in the same two feature inputs, but each processes those inputs in a different way. The first neuron outputs as an OR operator, and the second as a NAND operator. These two neurons form what is called a **layer**, since they both process the same input.\n",
    "\n",
    "The output of these two neurons is then fed into a final third neuron at a second layer, which processes previous outputs as inputs to an AND operator. The output of this configuration of neurons is the output of the XOR operator (with respect to the original inputs).\n",
    "\n",
    "Models that employ a network of multiple neurons are called **artificial neural networks**. Networks like the one above more closely resemble the connected multi-neuron structure originally observed by Golgi.\n",
    "\n",
    "The neural network shown above has three different layers: an **input** layer (the set of inputs to the model), a **hidden layer** (any layer that is not the input layer or final layer), and a final **output** layer (providing final outputs as opposed to intermediate activations).\n",
    "\n",
    "As we will see in a future class, networks such as these, with at least one hidden layer, are extremely general and powerful learning models that have been employed both to model many aspects of cognition as well as many practical engineering problems that also require learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
