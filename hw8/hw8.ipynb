{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96944fef",
   "metadata": {},
   "source": [
    "# Fitting Decision Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e376564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q otter-grader\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw8.ipynb\")\n",
    "\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eed340",
   "metadata": {},
   "source": [
    "When we previously assessed categorization models, we evaluated their ability to predict the empirical proportion of participants that assign a new stimulus to category A versus category B. As we've mentioned before, the same can be done for decision models, where we analogously predict the proportion of participants choosing gamble A over gamble B.\n",
    "\n",
    "Below are three familiar choice problems that we've seen before. Since pandas dataframes aren't as well suited to this kind of data, we provide each choice problem as a separate Python dictionary within a Python list. For each, we can see the relevant outcomes and probabilities. Additionally, we now also include `prob_chose_A`, which is the empirical proportion of participants choosing gamble A over gamble B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc1f6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"A_outcomes\": np.array([1000., 0.]),\n",
    "        \"B_outcomes\": np.array([500.]),\n",
    "        \"A_probs\": np.array([0.5, 0.5]), \n",
    "        \"B_probs\": np.array([1.0]),\n",
    "        \"prob_chose_A\": 0.08,\n",
    "    },\n",
    "    {\n",
    "        \"A_outcomes\": np.array([-100., 100.]),\n",
    "        \"B_outcomes\": np.array([0.]),\n",
    "        \"A_probs\": np.array([0.5, 0.5]),\n",
    "        \"B_probs\": np.array([1.0]),\n",
    "        \"prob_chose_A\": 0.33,\n",
    "    },\n",
    "    {\n",
    "        \"A_outcomes\": np.array([500., 0.]),\n",
    "        \"B_outcomes\": np.array([5.]),\n",
    "        \"A_probs\": np.array([0.01, 0.99]),\n",
    "        \"B_probs\": np.array([1.0]),\n",
    "        \"prob_chose_A\": 0.60,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9014f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As previously discussed, we can use decision models to predict these proportions by converting gamble values to probabilities using the Luce choice rule:\n",
    "$$\\frac{e^{ V(A)}}{e^{V(A)} + e^{V(B)}},$$\n",
    "\n",
    "where $V(A)$ is the value of gamble A and $V(B)$ is the value of gamble B.\n",
    "\n",
    "This rule is identical to the similarity-choice rule used in our categorization models, but instead of taking similarity values as input, it takes values of gambles as input. Thus, just like our categorization models, we can include a parameter analogous to the sensitivity parameter. In the context of decision models, this model is often called the temperature parameter $\\large{\\tau}$. The modified Luce choice rule then becomes:\n",
    "\n",
    "$$\\frac{e^{ V(A) \\large{\\tau}}}{e^{V(A) \\large{\\tau}} + e^{V(B) \\large{\\tau}}}.$$\n",
    "\n",
    "Note that $\\large{\\tau}$ is still a \"sensitivity\" parameter and thus functions the same. That is, lower values of $\\large{\\tau}$ lead to less differentiated gamble values and probabilities closer to 0.5, and higher values of $\\large{\\tau}$ lead to more differentiated gamble values and more exaggerated probabilities that are further from 0.5.\n",
    "\n",
    "**Assignment:** Find the parameters ($\\alpha$, $\\lambda$, $\\gamma$, and $\\large{\\tau}$) of the decision model that best predicts human response proportions in the choice problems in `data`. Use MSE to score each combination of the parameters. Store the best parameters in variables called `best_alpha`, `best_lambda`, `best_gamma`, and `best_tau`. And store the best MSE score in `best_score`.\n",
    "\n",
    "**Note 1:** The specific parameter values to evaluate are provided below (e.g., `alphas_to_test`).\n",
    "\n",
    "**Note 2:** You will need to reference the \"Models 1\", \"Models 2\", \"Decisions 1\" and \"Decisions 2\" labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b05f4963",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# do not change\n",
    "alphas_to_test = np.arange(0.01, 1.01, 0.01)\n",
    "lambdas_to_test = np.linspace(0.0, 3.5, 36)\n",
    "gammas_to_test = np.arange(0.1, 1.1, 0.1)\n",
    "taus_to_test = np.arange(0.01, 0.11, 0.01)\n",
    "\n",
    "# Your code here\n",
    "def loss_aversion(x, alpha, lam):\n",
    "    return np.power(x, alpha) if x >= 0 else -lam * np.power(-x, alpha)\n",
    "\n",
    "def pi(p, gamma):\n",
    "    return (p ** gamma) / np.power(p ** gamma + (1 - p) ** gamma, 1 / gamma)\n",
    "\n",
    "def prospect_theory(outcomes, probs, alpha, lam, gamma):\n",
    "    v  = np.array([loss_aversion(x, alpha, lam) for x in outcomes])\n",
    "    w  = np.array([pi(p, gamma) for p in probs])\n",
    "    return np.sum(w * v)\n",
    "\n",
    "best_score  = np.inf\n",
    "best_alpha  = None\n",
    "best_lambda = None\n",
    "best_gamma  = None\n",
    "best_tau    = None\n",
    "\n",
    "for alpha, lam, gamma, tau in itertools.product(alphas_to_test, lambdas_to_test, gammas_to_test, taus_to_test):\n",
    "\n",
    "    sq_errs = []\n",
    "    for d in data:\n",
    "        V_A = prospect_theory(d[\"A_outcomes\"], d[\"A_probs\"], alpha, lam, gamma)\n",
    "        V_B = prospect_theory(d[\"B_outcomes\"], d[\"B_probs\"], alpha, lam, gamma)\n",
    "        \n",
    "        P_A = np.exp(tau * V_A) / (np.exp(tau * V_A) + np.exp(tau * V_B))\n",
    "\n",
    "        sq_errs.append((P_A - d[\"prob_chose_A\"])**2)\n",
    "\n",
    "    mse = np.mean(sq_errs)\n",
    "\n",
    "    if mse < best_score:\n",
    "        best_score  = mse\n",
    "        best_alpha  = alpha\n",
    "        best_lambda = lam\n",
    "        best_gamma  = gamma\n",
    "        best_tau    = tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9624de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": [
      0,
      0,
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(best_alpha, float)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(best_lambda, float)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(best_gamma, float)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(best_tau, float)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(best_score, float)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
