{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "18142c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7403a",
   "metadata": {},
   "source": [
    "## Prototype Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8f4d4",
   "metadata": {},
   "source": [
    "Generate the prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b0876cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prototypes(X_train, y_train):\n",
    "    ai_proto = np.mean(X_train[y_train == 'ai'], axis=0)\n",
    "    real_proto = np.mean(X_train[y_train == 'real'], axis=0)\n",
    "    return ai_proto, real_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eb42a",
   "metadata": {},
   "source": [
    "Categorize each exemplar in the training set by distance to prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "aee13e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prototype_predict(ai_proto, real_proto, stims):\n",
    "    predictions = []\n",
    "\n",
    "    for stim in stims:\n",
    "        dist_ai = -np.linalg.norm(stim - ai_proto)\n",
    "        dist_real = -np.linalg.norm(stim - real_proto)\n",
    "        if dist_ai > dist_real:\n",
    "            predictions.append('ai')\n",
    "        else:\n",
    "            predictions.append('real')\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd922d3",
   "metadata": {},
   "source": [
    "## Exemplar Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb42c2",
   "metadata": {},
   "source": [
    "Generate lists of exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "900a42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_exemplars(X_train, y_train):\n",
    "    exemplars = {\n",
    "        'ai': X_train[y_train == 'ai'],\n",
    "        'real': X_train[y_train == 'real']\n",
    "    }\n",
    "    return exemplars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbd195",
   "metadata": {},
   "source": [
    "Categorize each exemplar based on highest similarity score to each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b445a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exemplar_predict(stims, exemplars):\n",
    "    predictions = []\n",
    "    for stimulus in stims:\n",
    "        dist_ai = np.linalg.norm(exemplars['ai'] - stimulus, axis=1)\n",
    "        ai_similar = np.sum(np.exp(-dist_ai))\n",
    "\n",
    "        dist_real = np.linalg.norm(exemplars['real'] - stimulus, axis=1)\n",
    "        real_similar = np.sum(np.exp(-dist_real))\n",
    "        \n",
    "        if ai_similar > real_similar:\n",
    "            predictions.append('ai')\n",
    "        else:\n",
    "            predictions.append('real')\n",
    "            \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ed46a",
   "metadata": {},
   "source": [
    "### Results (with ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "50a3631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dims  prototype_acc  exemplar_acc    ml_acc\n",
      "0     1       0.544108      0.603992  0.582099\n",
      "1     2       0.535737      0.602061  0.588538\n",
      "2     3       0.544108      0.602061  0.598197\n",
      "3     4       0.544108      0.602061  0.594977\n",
      "4     5       0.544108      0.602061  0.599485\n",
      "5    10       0.544108      0.602061  0.602061\n",
      "6    20       0.544108      0.602061  0.609788\n",
      "7    30       0.544108      0.602061  0.609788\n",
      "8    50       0.544108      0.602061  0.609788\n",
      "9   100       0.544108      0.602061  0.609788\n"
     ]
    }
   ],
   "source": [
    "# [1, 2, 3, 4, 5, 10, 20, 30, 50, 100]\n",
    "pca_dfs = {\n",
    "    1:  'df_pca_1',\n",
    "    2:  'df_pca_2',\n",
    "    3:  'df_pca_3',\n",
    "    4:  'df_pca_4',\n",
    "    5:  'df_pca_5',\n",
    "    10: 'df_pca_10',\n",
    "    20: 'df_pca_20',\n",
    "    30: 'df_pca_30',\n",
    "    50: 'df_pca_50',\n",
    "    100:'df_pca_100'\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "df_resp = pd.read_csv(\"./DATA AND R CODE/eachresponse.csv\")\n",
    "df_resp = df_resp.dropna(how='any')\n",
    "\n",
    "for d, df_pca in pca_dfs.items():\n",
    "    df = pd.read_pickle(df_pca)  \n",
    "    df[\"image\"] = df[\"image\"].str.extract(r'\\((\\d+)\\)', expand=False)\n",
    "    df[\"image\"] = df[\"image\"].astype(int)\n",
    "    \n",
    "    df_merged = pd.merge(df_resp, df, on=\"image\", how=\"inner\")\n",
    "    pca_columns = [i for i in range(0, d)]\n",
    "    \n",
    "    df_merged = df_merged[df_merged[\"confidence\"] >= 4]\n",
    "    \n",
    "    X = df_merged[pca_columns].values\n",
    "    y = df_merged[\"choice\"].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Prototype\n",
    "    ai_proto, real_proto = gen_prototypes(X_train, y_train)\n",
    "    proto_preds = prototype_predict(ai_proto, real_proto, X_test)\n",
    "    proto_acc = accuracy_score(y_test, proto_preds)\n",
    "\n",
    "    # Exemplar\n",
    "    exemplars = gen_exemplars(X_train, y_train)\n",
    "    exemplar_preds = exemplar_predict(X_test, exemplars)\n",
    "    exemplar_acc = accuracy_score(y_test, exemplar_preds)\n",
    "\n",
    "    # ML (RidgeClassifier)\n",
    "    clf = RidgeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    ml_preds = clf.predict(X_test)\n",
    "    ml_acc = accuracy_score(y_test, ml_preds)\n",
    "\n",
    "    results.append({\n",
    "        \"dims\": d,\n",
    "        \"prototype_acc\": proto_acc,\n",
    "        \"exemplar_acc\": exemplar_acc,\n",
    "        \"ml_acc\": ml_acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
