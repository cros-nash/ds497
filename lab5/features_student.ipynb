{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From spaces to features\n",
    "\n",
    "Today:\n",
    "- **We will be working in groups of two.**\n",
    "- **Choose a new partner that you haven't worked with before.**\n",
    "\n",
    "Given similarity data, NMDS can recover psychological representations that are dimensional/spatial (i.e., points in space).\n",
    "\n",
    "However, consider mental concepts such as \"is_a_multiple_of_two\". Whether or not a number is a multiple of two is a discrete **feature** of a number, and may not be well captured by a continuous psychological dimension. If some mental objects are represented via sets of discrete features, how can we infer those kinds representations?\n",
    "\n",
    "This also opens up the broader question of what other representational structures the mind might employ (spaces, features, others?), and how we might infer each. Today we will focus on **binary** feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load a representation of eight animals that consists of six binary features. Recall that psychological representations of any kind are not directly observable, but the example below will help us think about how we might infer them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mammal</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Lives in Water</th>\n",
       "      <th>Has Fur</th>\n",
       "      <th>Carnivore</th>\n",
       "      <th>Domesticated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horse</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salamander</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eagle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldfish</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dolphin</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mammal  Pet  Lives in Water  Has Fur  Carnivore  Domesticated\n",
       "Dog              1    1               0        1          1             1\n",
       "Cat              1    1               0        1          1             1\n",
       "Horse            1    0               0        1          0             1\n",
       "Salamander       0    0               1        0          1             0\n",
       "Snake            0    0               0        0          1             0\n",
       "Eagle            0    0               0        0          1             0\n",
       "Goldfish         0    1               1        0          0             1\n",
       "Dolphin          1    0               1        0          1             0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_animal_feats = load_animal_features()\n",
    "df_animal_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that representations are related to similarity (i.e., human similarity judgments). In the case of NMDS and spatial representations, similarity values $s_{ij}$ give us hints about what representations produce them by telling us about representational distance.\n",
    "\n",
    "In the case of discrete features, similarity values $s_{ij}$ give us hints about two things: (1) the features of objects and (2) their \"importance\" or \"salience\".\n",
    "\n",
    "Shepard & Arabie (1979) proposed that the similarity between objects defined by features is a weighted sum of shared features. It implies simply that objects are similar to the extent that they share important features.\n",
    "\n",
    "In particular, given $m$ features (such as in `df_animal_feats` where $m=6$), estimated similarity $\\hat{s}_{ij}$ is defined as:\n",
    "\n",
    "$\\hat{s}_{ij} = \\sum_{k=1}^{m} w_k f_{ik} f_{jk}$,\n",
    "\n",
    "where:\n",
    "- $f_{ik}$ is the $k{^\\text{th}}$ feature for object $i$ (e.g., the binary value for \"Lives in Water\"),\n",
    "- $f_{jk}$ is the $k{^\\text{th}}$ feature for object $j$, and\n",
    "- $w_k$ is a non-negative weight corresponding to the $k{^\\text{th}}$ feature.\n",
    "\n",
    "If objects $i$ and $j$ share feature $k$ (i.e., $f_{ik} = f_{jk} = 1$), then the product $f_{ik} f_{jk} = 1 \\times 1 = 1$. Otherwise, $f_{ik} f_{jk} = 0$.\n",
    "\n",
    "Note that if objects $i$ and $j$ share feature $k$, then $w_k f_{ik} f_{jk} = w_k \\times 1 = w_k$.\n",
    "\n",
    "Thus, the weighted sum is a sum of the weights for only the shared features.\n",
    "\n",
    "Because weights $w_k$ are non-negative, the fact that a feature is shared will never decrease similarity, which makes intuitive sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "To understand how shared features tell us something about similarity, create a function called `compute_counts` that takes in a dataframe like `df_animals` and returns a similarity matrix as a dataframe where each item $(i, j)$ in the matrix is the count:\n",
    "\n",
    "$\\text{count}_{ij} = \\sum_{k=1}^{m} f_{ik} f_{jk}$.\n",
    "\n",
    "The indices and columns of the output dataframe should match the input (e.g., `df_animals.index`).\n",
    "\n",
    "Set all items of the matrix where $i<=j$ to `np.nan` such that only the lower triangle is filled with similarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Salamander</th>\n",
       "      <th>Snake</th>\n",
       "      <th>Eagle</th>\n",
       "      <th>Goldfish</th>\n",
       "      <th>Dolphin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horse</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salamander</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snake</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eagle</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldfish</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dolphin</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dog  Cat  Horse  Salamander  Snake  Eagle  Goldfish  Dolphin\n",
       "Dog         NaN  NaN    NaN         NaN    NaN    NaN       NaN      NaN\n",
       "Cat         5.0  NaN    NaN         NaN    NaN    NaN       NaN      NaN\n",
       "Horse       3.0  3.0    NaN         NaN    NaN    NaN       NaN      NaN\n",
       "Salamander  1.0  1.0    0.0         NaN    NaN    NaN       NaN      NaN\n",
       "Snake       1.0  1.0    0.0         1.0    NaN    NaN       NaN      NaN\n",
       "Eagle       1.0  1.0    0.0         1.0    1.0    NaN       NaN      NaN\n",
       "Goldfish    2.0  2.0    1.0         1.0    0.0    0.0       NaN      NaN\n",
       "Dolphin     2.0  2.0    1.0         2.0    1.0    1.0       1.0      NaN"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "def compute_counts(df):\n",
    "    sim_matrix = np.zeros((len(df), len(df)))\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df)):\n",
    "            if i <= j:\n",
    "                sim_matrix[i, j] = np.nan\n",
    "            else:\n",
    "                sim_matrix[i, j] = np.sum(df.iloc[i] * df.iloc[j])\n",
    "            \n",
    "    return pd.DataFrame(sim_matrix, index=df.index, columns=df.index)\n",
    "    \n",
    "    \n",
    "    \n",
    "# do not change\n",
    "df_counts = compute_counts(df_animal_feats)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isnan(df_counts.loc['Dog', 'Dog']) and df_counts.loc['Cat', 'Dog'] == 5.0:\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, dog and cat are the most similar in the sense that they share the most features. \n",
    "\n",
    "However, the above count-based pattern of similarity can change depending on how \"important\" each shared feature is (i.e., how big each $w_k$ value is).\n",
    "\n",
    "Let's now incorporate those weights.\n",
    "\n",
    "**Exercise 2:**\n",
    "\n",
    "Create a function called `compute_similarity` that takes in a dataframe like `df_animals` and returns a similarity matrix as a dataframe where each item $(i, j)$ in the matrix is the count:\n",
    "\n",
    "$\\hat{s}_{ij} = \\sum_{k=1}^{m} w_k f_{ik} f_{jk}$.\n",
    "\n",
    "The indices and columns of the output dataframe should match the input (e.g., `df_animals.index`).\n",
    "\n",
    "Set all items of the matrix where $i<=j$ to `np.nan` such that only the lower triangle is filled with similarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def compute_similarity(df, weight):\n",
    "    weight = np.array(weight)\n",
    "    \n",
    "    F = df.values\n",
    "    F_weighted = F * weight\n",
    "    \n",
    "    S = np.dot(F_weighted, F.T)\n",
    "    \n",
    "    sim_df = pd.DataFrame(S, index=df.index, columns=df.index)\n",
    "    \n",
    "    sim_df.values[np.triu_indices_from(sim_df)] = np.nan\n",
    "    \n",
    "    return sim_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "_ = compute_similarity(df_animal_feats, np.ones(df_animal_feats.shape[1])*0.5)\n",
    "if np.isnan(_.loc['Dog', 'Dog']) and _.loc['Cat', 'Dog'] == 5.0*0.5:\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1:** Compute animal similarity using a numpy of weights all set to 0.25. Store the result in a dataframe called `df_sim_estimated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "df_sim_estimated = compute_similarity(df_animal_feats, np.ones(df_animal_feats.shape[1])*0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isnan(df_sim_estimated.loc['Dog', 'Dog']) and df_sim_estimated.loc['Cat', 'Dog'] == 1.25:\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance weights $w_k$ are another part of the mental representation that we can't directly observe.\n",
    "\n",
    "However, given observable human similarity data, we can infer the weights.\n",
    "\n",
    "Below we load corresponding animal similarity data (average judgments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Salamander</th>\n",
       "      <th>Snake</th>\n",
       "      <th>Eagle</th>\n",
       "      <th>Goldfish</th>\n",
       "      <th>Dolphin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horse</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salamander</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snake</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eagle</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldfish</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dolphin</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dog   Cat  Horse  Salamander  Snake  Eagle  Goldfish  Dolphin\n",
       "Dog          NaN   NaN    NaN         NaN    NaN    NaN       NaN      NaN\n",
       "Cat         0.70   NaN    NaN         NaN    NaN    NaN       NaN      NaN\n",
       "Horse       0.45  0.45    NaN         NaN    NaN    NaN       NaN      NaN\n",
       "Salamander  0.05  0.05   0.00         NaN    NaN    NaN       NaN      NaN\n",
       "Snake       0.05  0.05   0.00        0.05    NaN    NaN       NaN      NaN\n",
       "Eagle       0.05  0.05   0.00        0.05   0.05    NaN       NaN      NaN\n",
       "Goldfish    0.25  0.25   0.05        0.15   0.00   0.00       NaN      NaN\n",
       "Dolphin     0.35  0.35   0.30        0.20   0.05   0.05      0.15      NaN"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_animal_sim = load_sim_data()\n",
    "df_animal_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the set of weights such that our similarity estimates $\\hat{s}_{ij}$ are as close as possible to the actual similarities $s_{ij}$.\n",
    "\n",
    "Similar to our definition of stress, we can define a measure of total squared error:\n",
    "\n",
    "$SE = \\sum_{i>j} (s_{ij} - \\hat{s}_{ij})^2$.\n",
    "\n",
    "We want to find a set of weights that make this error as small as possible.\n",
    "\n",
    "**Exercise 3:**\n",
    "\n",
    "Create a function called `compute_error` that takes in a dataframe like `df_animal_sim` of real similarity values and a dataframe like `df_animal_sim` of estimated similarity values and returns the summed squared error as a single float value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def compute_error(real_df, estimated_df):\n",
    "    return np.nansum((real_df - estimated_df).values**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "_1 = compute_error(df_animal_sim, df_animal_sim)\n",
    "_2 = compute_error(\n",
    "    df_animal_sim, \n",
    "    compute_similarity(\n",
    "        df_animal_feats, \n",
    "        np.ones(df_animal_feats.shape[1])*0.5\n",
    "    )\n",
    ")\n",
    "if np.isclose(_1, 0) and np.isclose(_2, 10.769999999999998):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1:** Call `compute_error` with arguments that will demonstrate the best possible error attainable with respect to the animal data. Store the result in `best_possible_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "best_possible_error = compute_error(df_animal_sim, df_animal_sim)\n",
    "best_possible_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isclose(best_possible_error, 0):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $\\hat{s}_{ij} = \\sum_{k=1}^{m} w_k f_{ik} f_{jk}$, and thus we can write the error as:\n",
    "\n",
    "$SE = \\sum_{i>j} (s_{ij} - \\hat{s}_{ij})^2 = \\sum_{i>j} (s_{ij} - \\sum_{k=1}^{m} w_k f_{ik} f_{jk})^2$.\n",
    "\n",
    "Notice that all terms above are currently given except for each weight $w_k$. We want to find the weights that make the above sum as small as possible.\n",
    "\n",
    "**Exercise 3.2:** Compute error when weights are all set to 1.0, and store the result in `error_when_weights_are_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "error_when_weights_are_1 = compute_error(df_animal_sim, compute_similarity(df_animal_feats, np.ones(df_animal_feats.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isclose(error_when_weights_are_1, float('30000000000070.95'[::-1])):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.3:** Compute error when weights are all set to 0.5, and store the result in `error_when_weights_are_smaller`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "error_when_weights_are_smaller = compute_error(df_animal_sim, compute_similarity(df_animal_feats, np.ones(df_animal_feats.shape[1])*0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isclose(error_when_weights_are_smaller, float('899999999999967.01'[::-1])):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, weights are equal only as an example. Ultimately we will want unequal weights (i.e., that represent differences in feature importance) and that minimize the error.\n",
    "\n",
    "**Exercise 4:** Define a function called `error_given_weights` that takes a numpy array of weights as input and returns summed squared error as a single float value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def error_given_weights(weights):\n",
    "    return compute_error(df_animal_sim, compute_similarity(df_animal_feats, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isclose(error_given_weights(np.ones(df_animal_feats.shape[1])), 59.07000000000003):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the input weights that \"minimize\" the output of the `error_given_weights` above.\n",
    "\n",
    "We can do this using the `minimize` function from `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minimize` takes as input the function to minimize and an initial guess for the input that will minimize it. \n",
    "\n",
    "It returns an object with an attribute called `x` (e.g., `my_output.x`) containing the inputs that will minimize the function.\n",
    "\n",
    "In our case, the function to minimize is `error_given_weights`, and an initial guess for the weights can be all ones: `np.ones(df_animal_feats.shape[1])`.\n",
    "\n",
    "**Exercise 5:** Use the `minimize` function to find the importance weights that best explain human similarity judgments. Store the resulting weights in a numpy array called `best_animal_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "best_animal_weights = minimize(error_given_weights, np.ones(df_animal_feats.shape[1])).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.all(np.isclose(best_animal_weights, [0.3, 0.2, 0.15, 0.1, 0.05, 0.05], atol=1e-5)):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best weights found should indeed be unequal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30000156, 0.19999464, 0.14999923, 0.09999255, 0.04999998,\n",
       "       0.0500062 ])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_animal_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error in reconstructing similarity given these best weights should be much smaller than the error we guessed before (e.g., equal weights of 1), and hopefully close to 0.\n",
    "\n",
    "**Exercise 5.1:** Compute the error given the best weights and store the result in `error_given_best_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "error_given_best_weights = error_given_weights(best_animal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if np.isclose(error_given_best_weights, 0.0):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.2:** Based on the weights we found, which feature does the mind think is most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = \"Mammal\"\n",
    "# answer1 = \"Pet\"\n",
    "# answer1 = \"Lives in Water\"\n",
    "# answer1 = \"Has Fur\"\n",
    "# answer1 = \"Carnivore\"\n",
    "# answer1 = \"Domesticated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR SOLUTION\n",
    "\n",
    "# DON'T CHANGE THIS CELL\n",
    "if 'lam'[::-1] in answer1:\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, what we've accomplished so far is the easy part. \n",
    "\n",
    "In the previous example, the feature matrix was given for the sake of example, but recall that such features are not actually observable and must be inferred.\n",
    "\n",
    "As we saw, given a feature matrix, inferring importance weights is relatively straightforward. However, inferring the feature matrix in the first place is much more difficult.\n",
    "\n",
    "One shortcut researchers sometimes take is to simply predefine a large set of possible features and ask people questions such as \"Does this animal have the feature is_dangerous?\". Data from such experiments are called **feature norms**. However, these experimental designs have several issues, most notably that the researcher is unlikely to choose the correct superset of features to ask about.\n",
    "\n",
    "Instead, we would like to infer the features from the similarity data. Unfortunately, this presents a combinatorial optimization problem that is an open problem in cognitive psychology. We will explore the search for such features in a future lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
